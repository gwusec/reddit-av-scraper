{
  "subreddit": "LocalLLaMA",
  "post_id": "1i2b2eo",
  "title": "Meta Prompts - Because Your LLM Can Do Better Than Hello World",
  "body": "Alright, fasten your seatbelts. We're taking a ride through meta-prompting land.\n\nTL;DR:https://streamable.com/vsgcksWe create this by just using two prompts, and what you see in the video isn't even 1/6th of everything. It's just boring to watch 10 minutes of scrolling. With just two prompts we deconstruct an arbitrary complex project into such small parts even LLMs can do it\n\nDefault meta prompt collection:https://gist.github.com/pyros-projects/c77402249b5b45f0a501998870766ae9\n\nMeta prompt collection with prompts creating summaries and context sync (use them when using Cline or other coding assistants):https://gist.github.com/pyros-projects/f6430df8ac6f1ac37e5cfb6a8302edcf\n\nHow to use them:https://gist.github.com/pyros-projects/e2c96b57ac7883076cca7bc3dc7ff527\n\nEven if it's mostly about o1 and similar reasoning models everything can also be applied to any other LLM\n\nMeta-prompts originated fromthis paper, written by a guy at an indie research lab and another guy from a college with a cactus garden. Back then, everyone was obsessed with role-playing prompts like:“You are an expert software engineer…”\n\nThese two geniuses thought after eating some juicy cacti from the garden:“What if the LLM came up with its own expert prompt and decided what kind of expert to role-play?”The result? The first meta-prompt was born.\n\nYou are Meta-Expert, an extremely clever expert with the unique ability to collaborate with multiple experts (such as Expert Problem Solver, Expert Mathematician, Expert Essayist, etc.) to tackle any task and solve complex problems. Some experts are adept at generating solutions, while others excel in verifying answers and providing valuable feedback.\n\nYou also have special access to Expert Python, which has the unique ability to generate and execute Python code given natural-language instructions. Expert Python is highly capable of crafting code to perform complex calculations when provided with clear and precise directions. It is especially useful for computational tasks.\n\nAs Meta-Expert, your role is to oversee the communication between the experts, effectively utilizing their skills to answer questions while applying your own critical thinking and verification abilities.\n\nTo communicate with an expert, type its name (e.g., \"Expert Linguist\" or \"Expert Puzzle Solver\"), followed by a colon:, and then provide detailed instructions enclosed within triple quotes. For example:\n\nEnsure that your instructions are clear and unambiguous, including all necessary information within the triple quotes. You can also assign personas to the experts (e.g., \"You are a physicist specialized in...\").\n\nGuidelines:\n\nInteract with only one expert at a time, breaking complex problems into smaller, solvable tasks if needed.\n\nEach interaction is treated as an isolated event, so always provide complete details in every call.\n\nIf a mistake is found in an expert's solution, request another expert to review, compare solutions, and provide feedback. You can also request an expert to redo their calculations using input from others.\n\nImportant Notes:\n\nAll experts, except yourself, have no memory. Always provide full context when contacting them.\n\nExperts may occasionally make errors. Seek multiple opinions or independently verify solutions if uncertain.\n\nBefore presenting a final answer, consult an expert for confirmation. Ideally, verify the final solution with two independent experts.\n\nAim to resolve each query within 15 rounds or fewer.\n\nAvoid repeating identical questions to experts. Carefully examine responses and seek clarification when needed.\n\nFinal Answer Format:Present your final answer in the following format:\n\nFor multiple-choice questions, select only one option. Each question has a unique answer, so analyze the information thoroughly to determine the most accurate and appropriate response. Present only one solution if multiple options are available.\n\nThe idea was simple but brilliant: you’d give the LLM this meta-prompt, execute it, append the answers to the context, and repeat until it had everything it needed.\n\nCompared to other prompting strategies, meta-prompts outperform many of them:\n\n![[https://imgur.com/a/Smd0i1m]]\n\nIf you’re curious, you can check outMeta-Prompting on GitHubfor some early examples from the paper. Just keep in mind, this was during the middle ages of LLM research, when prompting was actually still researched. But surprisingly the og meta prompt still holds up and can be quite effective!\n\nSince currently there's a trend toward imprinting prompting strategies directly into LLMs (like CoT reasoning), this might be another approach worth exploring. Will definitely try it out when our server farm has some capacity free.\n\nLet’s talk about the galaxy-brain takes I keep hearing:\n\n“LLMs are only useful for small code snippets.”\n\n“I played around with o1 for an hour and decided it sucks.”\n\nWhy do people think this? Because their prompts are hot garbage, like:\n\n“Generate me an enterprise-level user management app.”\n\n“Prove this random math theorem.”\n\nThat’s it. No context. No structure. No plan. Then they’re shocked when the result is either vague nonsense or flat-out wrong. Like, have you ever managed an actual project? Do you tell your dev team,“Write me a AAA game. Just figure it out,”and expect Baldur's Gate?\n\nNo. Absolutely not. But somehow it seems to be expected that LLMs deliver superhuman feats even tho people love to scream out how stupid they are...\n\nHere’s the truth:LLMs can absolutely handle enterprise-level complexity. if you prompt them like they’re part of an actual project team.That’s where meta-prompts come in. They turn chaos into order and give LLMs the context, process, and structure they need to perform like experts. It's basically in-context fine-tuning\n\nSo, if you're a dev or architect looking for a skill that's crazy relevant now and will stay relevant for the next few months (years? who knows), get good at meta-prompts.\n\nI expect that with o3, solution architects won't manage dev teams anymore, they'll spend their days orchestrating meta-prompts. Some of us are already way faster using just o1 Pro than working with actual human devs, and I can't even imagine what a bot with a 2770 ELO on Codeforces will do to the architect-dev relationship.\n\nNow, are meta-prompts trivially easy? Of course not. (Shoutout to my friends yesterday who told me\"prompt engineering doesn't exist,\"lol.) They require in-depth knowledge of project management, software architecture, and subject-matter expertise. They have to be custom-tailored to your personal workflow and work quirks. That's the reason I probably saw them being mentioned on reddit like only twice.\n\nBut I promise anyone can understand the basics. The rest is experience. Try them out, make them your own, and you'll never look back, because for the first time, you'll actually be using an LLM instead of wasting time with it. Then you have the keys to your own personal prompting wonderland.\n\nThis is how probably the smallest completely self-contained meta prompt pipeline looks like which can solve any kind of projects or tasks (at least I couldn't make them smaller the last few days when I was writing this)\n\nMeta Prompt 01 - Planning\n\nMeta Prompt 02 - Iterative chain prompting\n\nMeta Prompt 03 - Task selection prompting(only needed if your LLM doesn't like #2)\n\nWhat do I mean with pipeline? Well the flow works like this. Give LLM prompt 01. When it's done generating, give it prompt 02. Then you continue giving it prompt 02 until you are done with the project. The prompt forces the LLM to iterate upon itself so to speak.\n\nHere a more detailed \"how to\":https://gist.github.com/pyros-projects/e2c96b57ac7883076cca7bc3dc7ff527\n\nInstead of dumping a vague brain dump on the model and hoping for magic, you teach ithow to think. You tell it:\n\nWhat you want (context)Example:“Build a web app that analyzes GitHub repos and generates AI-ready documentation.”\n\nHow to think about it (structure)Example:“Break it into components, define tasks, and create technical specs.”\n\nWhat to deliver (outputs)Example:“A YAML file with architecture, components, and tasks.”\n\nMeta-prompts follow a pattern: they defineroles,rules, anddeliverables. Let’s break it down with the ones I’ve created for this guide:\n\nPlanning Meta-Prompthttps://gist.github.com/pyros-projects/c77402249b5b45f0a501998870766ae9#file-01_planning-md\n\nRole:You’re a software architect and technical project planner.\n\nRules: Break the project into a comprehensive plan with architecture, components, and tasks.\n\nDeliverables: A structured YAML file with sections likeProject Identity,Technical Architecture, andTask Breakdown.\n\nPossible outputhttps://gist.github.com/pyros-projects/c77402249b5b45f0a501998870766ae9#file-01_planning_output-md\n\nExecution Chain Meta-Prompthttps://gist.github.com/pyros-projects/c77402249b5b45f0a501998870766ae9#file-02_prompt_chain-md\n\nRole:You’re an expert at turning plans into actionable chunks.\n\nRules: Take the project plan and generate coding prompts and review prompts for each task.\n\nDeliverables: Sequential execution and review prompts, including setup, specs, and criteria.\n\nPossible output:https://gist.github.com/pyros-projects/c77402249b5b45f0a501998870766ae9#file-02_prompt_chain_potential_output-md\n\nTask Selection Meta-Prompthttps://gist.github.com/pyros-projects/c77402249b5b45f0a501998870766ae9#file-03_prompt_chain_alt-md\n\nRole:You’re a project manager keeping the workflow smooth.\n\nRules: Analyze dependencies and select the next task while preserving context.\n\nDeliverables: The next coding and review prompt, complete with rationale and updated state.\n\nEach meta-prompt builds on the last, creating a self-contained workflow where the LLM isn’t just guessing—it’s following a logical progression.\n\nMeta-prompts turn LLMs into software architects, project managers, and developers, all locked inside a little text box. They enable:\n\nComprehensive technical planning\n\nIterative task execution\n\nClear rules and quality standards\n\nModular, scalable designs\n\nMeta-prompts are powerful, but they aren’t magic. They needyouto guide them. Here’s what to keep in mind:\n\nContext Is Everything.LLMs are like goldfish with a giant whiteboard. They only remember what’s in their current context. If your plan is messy or missing details, your outputs will be just as bad. Spend the extra time refining your prompts and filling gaps. A good meta prompt is designed to minimize these issues by keeping everything structured.\n\nModularity Is Key.Good meta-prompts break projects into modular, self-contained pieces. There is the saying \"Every project is deconstructable into something a junior dev could implement.\" I would go one step further: \"Every project is deconstructable into something an LLM could implement.\" This isn’t just a nice-to-have—it’s essential. Modularity is not only good practice, it makes things easier! Modularity will abstract difficulty away.\n\nIterate, Iterate, Iterate.Meta-prompts aren’t one-and-done. They’re a living system that you refine as the project evolves. Didn’t like the YAML output from the Planning Meta-Prompt? Tell the LLM what to fix and run it again. Got a weak coding prompt? Adjust it in the Execution Chain and rerun. You are the conductor—make the orchestra play in tune.\n\nMeta-Prompts Need Rules.If you’re too vague, the LLM will fill in the gaps with nonsense. That’s why good meta prompts are a huge book of rules, like defining how breaking down dependencies, defining interfaces, and creating acceptance criteria work. For example, theTask Selection Meta-Promptensures only the right task is chosen based on dependencies, context, and priorities. The rules make sure you aren't doing a task which the prerequisites are still missing for.\n\nMeta-Prompts Aren’t Easy, But They’re Worth It.Yeah, these prompts take effort. You need to know your project, your tools, and how to manage both. But once you’ve got the hang of them, they’re a game-changer. No more vague prompts. No more bad outputs. Just a smooth, efficient process where the LLM is a true teammate.\n\nAnd guess what? The LLM delivers, because now it knows what you actually need. Plus, you're guardrailing it against its worst enemy: its own creativity. Nothing good happens when you let an LLM becreative. Prompts like\"Generate me an enterprise-level user management app\"are like handing it a creativity license. Don't.\n\nMy personal meta-prompts I use at work are gigantic, easily 10 times more and bigger than what I prepared for this thread, and 100s of hours went into them to pack in corporate identity stuff, libraries we like to use a certain way, personal coding styles, and everything else so it feels like a buddy that can read my mind.\n\nThat's why I'm quite pissy if some schmuck who played with o1 for like an hour thinks they are some kind of authority in knowing what such a model has to offer. Especially if they aren't interested at all in help or learning how to get the best out of it. In the end, a model does what the prompter gives it, and therefore a model is just as good as the person using it.\n\nI can only recommend you learn them and you'll discover a whole new layer of how you can use LLMs, and I hope with this thread I could outline the very basics of them.\n\nCheersPyro\n\nPS: I have not forgotten that I have to make you guys a Anime Waifu with infinite context",
  "author": "hiepxanh",
  "comments": [
    {
      "author": "BackgroundAmoebaNine",
      "timestamp": "",
      "body": "A Quick History of Meta-PromptsMeta-prompts originated from this paper, written by a guy at an indie research lab and another guy from a college with a cactus garden. Back then, everyone was obsessed with role-playing prompts like: “You are an expert software engineer…”.These two geniuses thought after eating some juicy cacti from the garden: “What if the LLM came up with its own expert prompt and decided what kind of expert to role-play?” The result? The first meta-prompt was born.The above s my favorite part of this post lol. I miss reading fun tone like this ."
    },
    {
      "author": "LiteSoul",
      "timestamp": "",
      "body": "Plot twist: it was actually written by an LLM"
    },
    {
      "author": "Mother_Soraka",
      "timestamp": "",
      "body": "First of all, thank you very much.Trying this old basic example:Should i also paste the written code by the coding expert back to the conductor? or only the rest of the experts response?"
    },
    {
      "author": "No_Training9444",
      "timestamp": "",
      "body": "Would it also be possible to use these meta-prompts with Aider? Like, would it give any benefits to using it?Have you tried it?Because some models like DeepSeek v3 would be better at writing code and other models like gemini ir o1 would be more suitable for reasoning (planning)."
    },
    {
      "author": "H4ppy3nd",
      "timestamp": "",
      "body": "Thanks for sharing! I was playing arround with similar ideas lately. So, this helps me a lot. 🙂"
    },
    {
      "author": "hiepxanh",
      "timestamp": "",
      "body": "It should be agent manager, the master LLM control the swarm"
    },
    {
      "author": "Own-Contact4314",
      "timestamp": "",
      "body": "Spent 1 hr trying this meta prompting technique, step by step, doing back and forth conversation with multiple models, using O1 pro for most of the use cases and all it gave me a shitty looking frontend with everything stubbed, it behaves like a senior architect in faang with lots of experience but knows nothing, just know how to setup boilerplate code. too frustrated to write more a better approach was to just tell the LLM -\"WRITE COMPLETE CODE, DONT BE LAZY\"Atleast it gave me working codePrompting is very random, nobody has cracked it, its been a trend that the more complex your workflow is more intelligent you will be taken but transformers had taught us simple solutions are much better than complex ones."
    },
    {
      "author": "if47",
      "timestamp": "",
      "body": "In 2025, people still believe that prompt engineering is a thing."
    },
    {
      "author": "hiepxanh",
      "timestamp": "",
      "body": "Acutually yes it is, because you dont know how to use"
    }
  ]
}